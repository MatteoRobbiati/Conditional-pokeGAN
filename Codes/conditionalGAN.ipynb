{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lRUp5XDeHcaz"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-10T07:27:16.744174Z",
     "iopub.status.busy": "2022-07-10T07:27:16.743286Z",
     "iopub.status.idle": "2022-07-10T07:27:23.335082Z",
     "shell.execute_reply": "2022-07-10T07:27:23.333941Z",
     "shell.execute_reply.started": "2022-07-10T07:27:16.744072Z"
    },
    "id": "Mxc5UXDTHca1"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers \n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "#from tensorflow_docs.vis import embed\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import imageio\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_theme(font_scale=1.6, style='whitegrid') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QvIbRDqpHca3"
   },
   "source": [
    "## Constants and hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-10T07:27:26.348217Z",
     "iopub.status.busy": "2022-07-10T07:27:26.347617Z",
     "iopub.status.idle": "2022-07-10T07:27:26.353402Z",
     "shell.execute_reply": "2022-07-10T07:27:26.352454Z",
     "shell.execute_reply.started": "2022-07-10T07:27:26.348183Z"
    },
    "id": "1cqLeNgzHca4"
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "num_channels = 3\n",
    "num_classes = 3\n",
    "image_size = 64\n",
    "latent_dim = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-10T07:29:54.678927Z",
     "iopub.status.busy": "2022-07-10T07:29:54.678559Z",
     "iopub.status.idle": "2022-07-10T07:29:54.684861Z",
     "shell.execute_reply": "2022-07-10T07:29:54.683713Z",
     "shell.execute_reply.started": "2022-07-10T07:29:54.678897Z"
    }
   },
   "outputs": [],
   "source": [
    "types = ['Grass', 'Fire', 'Water']\n",
    "allowed_img_types = ['jpeg', 'png', 'jpg']\n",
    "\n",
    "IMG_SIZE = 64\n",
    "INPUT_SHAPE = (IMG_SIZE, IMG_SIZE, 3)\n",
    "BATCH_SIZE = 32\n",
    "Z_DIM = 100\n",
    "NUM_CLASSES = 3\n",
    "\n",
    "poke_img_path  = '../input/3class-pokemon/Poke_img'\n",
    "#poke_stat_path = '../input/pokemon-images-and-types/pokemon.csv'\n",
    "#satellite_path = '../input/landscape-classification/intel-image-classification/train'\n",
    "\n",
    "#pokemon_data = pd.read_csv(poke_stat_path)\n",
    "#pokemon_data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "II-CWxr4Hca6"
   },
   "source": [
    "## Loading the dataset and preprocessing it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-10T07:31:38.828709Z",
     "iopub.status.busy": "2022-07-10T07:31:38.827796Z",
     "iopub.status.idle": "2022-07-10T07:31:38.833488Z",
     "shell.execute_reply": "2022-07-10T07:31:38.832369Z",
     "shell.execute_reply.started": "2022-07-10T07:31:38.82867Z"
    },
    "id": "btAdIW64H6pW"
   },
   "outputs": [],
   "source": [
    "class_names = ['Fire', 'Water', 'Grass']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-10T07:31:40.714843Z",
     "iopub.status.busy": "2022-07-10T07:31:40.714479Z",
     "iopub.status.idle": "2022-07-10T07:31:43.916794Z",
     "shell.execute_reply": "2022-07-10T07:31:43.915735Z",
     "shell.execute_reply.started": "2022-07-10T07:31:40.714793Z"
    },
    "id": "qhVUZ3VTGac-",
    "outputId": "0f0e0063-4670-4b39-a74a-0e50f5c9ba48"
   },
   "outputs": [],
   "source": [
    "train_images = []\n",
    "train_labels = []\n",
    "for style in os.listdir(poke_img_path): \n",
    "        for poke in os.listdir(poke_img_path+'/'+str(style)):\n",
    "            train_labels.append(class_names.index(str(style)))\n",
    "            img = Image.open(poke_img_path+'/'+str(style)+'/' + str(poke)).convert('RGBA')\n",
    "            background = Image.new(\"RGBA\", img.size, (255, 255, 255))\n",
    "            img = Image.alpha_composite(background, img).convert('RGB')\n",
    "            img = img.resize((64,64))\n",
    "            train_images.append(np.asarray(img))\n",
    "\n",
    "train_images = np.reshape(train_images,(-1,64,64,3))\n",
    "train_images = train_images.astype(np.float32)\n",
    "train_images = train_images / 255.\n",
    "integ_labels = np.asarray(train_labels)\n",
    "train_labels = np.asarray(train_labels)\n",
    "\n",
    "train_labels = keras.utils.to_categorical(train_labels, 3)\n",
    "\n",
    "train_images.shape, train_labels.shape\n",
    "\n",
    "\n",
    "print(f\"Shape of training images: {train_images.shape}\")\n",
    "print(f\"Shape of training labels: {train_labels.shape}\")\n",
    "\n",
    "train_labels[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-10T07:32:04.527179Z",
     "iopub.status.busy": "2022-07-10T07:32:04.526833Z",
     "iopub.status.idle": "2022-07-10T07:32:04.863849Z",
     "shell.execute_reply": "2022-07-10T07:32:04.86285Z",
     "shell.execute_reply.started": "2022-07-10T07:32:04.52714Z"
    },
    "id": "JG6-y3J69Kxp"
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "BUFFER_SIZE = 1064\n",
    "\n",
    "# a bit of data augmentation\n",
    "data_augmentation = tf.keras.models.Sequential(\n",
    "  [\n",
    "    tf.keras.layers.RandomFlip(\"horizontal\"),\n",
    "    tf.keras.layers.RandomRotation(0.1),\n",
    "    tf.keras.layers.RandomZoom(0.1),\n",
    "  ]\n",
    ")\n",
    "\n",
    "\n",
    "def prepare(ds, shuffle=True, augment=True):\n",
    "  #shuffle elements\n",
    "  if shuffle:\n",
    "    ds = ds.shuffle(6000)\n",
    "  # Batch all datasets.\n",
    "  ds = ds.batch(batch_size)\n",
    "  # data augmentation \n",
    "  if augment:\n",
    "    ds = ds.map(lambda x, y: (data_augmentation(x, training=True), y), \n",
    "                num_parallel_calls=BUFFER_SIZE)\n",
    "  # Use buffered prefetching on all datasets.\n",
    "  return ds.prefetch(buffer_size=BUFFER_SIZE)\n",
    "\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
    "dataset = prepare(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-10T07:32:41.401085Z",
     "iopub.status.busy": "2022-07-10T07:32:41.400255Z",
     "iopub.status.idle": "2022-07-10T07:32:44.712323Z",
     "shell.execute_reply": "2022-07-10T07:32:44.711393Z",
     "shell.execute_reply.started": "2022-07-10T07:32:41.401047Z"
    },
    "id": "rJdyQDH7Al9Z",
    "outputId": "3ae4d3ee-d94b-41b9-8031-848a8eb28f54"
   },
   "outputs": [],
   "source": [
    "def show_random_sample(dataset):\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    for images, labels in dataset.take(1):\n",
    "        np_imgs = images.numpy()\n",
    "        np_labs = labels.numpy()\n",
    "\n",
    "    for i in range(20):\n",
    "        ax = plt.subplot(5, 5, i + 1)\n",
    "        plt.imshow(np_imgs[i])\n",
    "        plt.title(class_names[np.argmax(np_labs[i])])\n",
    "        plt.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('exsample.pdf')\n",
    "    plt.show()\n",
    "\n",
    "show_random_sample(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tym_psh1Hca-"
   },
   "source": [
    "## Calculating the number of input channel for the generator and discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-10T07:32:57.488304Z",
     "iopub.status.busy": "2022-07-10T07:32:57.487944Z",
     "iopub.status.idle": "2022-07-10T07:32:57.494494Z",
     "shell.execute_reply": "2022-07-10T07:32:57.493486Z",
     "shell.execute_reply.started": "2022-07-10T07:32:57.488262Z"
    },
    "id": "UNFmhvyOHcbA",
    "outputId": "8cfa6436-3ae6-466f-da93-71ac97b87435"
   },
   "outputs": [],
   "source": [
    "generator_in_channels = latent_dim + num_classes        # input of G\n",
    "discriminator_in_channels = num_channels + num_classes  # input of D\n",
    "print(generator_in_channels, discriminator_in_channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ee8KFYbnHcbC"
   },
   "source": [
    "## Creating the discriminator and generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-10T09:58:54.109879Z",
     "iopub.status.busy": "2022-07-10T09:58:54.109503Z",
     "iopub.status.idle": "2022-07-10T09:58:54.235624Z",
     "shell.execute_reply": "2022-07-10T09:58:54.234583Z",
     "shell.execute_reply.started": "2022-07-10T09:58:54.109845Z"
    },
    "id": "m-BneGvXHcbD",
    "outputId": "50b09408-5a2e-42c6-9af2-458bd8e80fe7"
   },
   "outputs": [],
   "source": [
    "# Create the discriminator.\n",
    "discriminator = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.InputLayer((64, 64, discriminator_in_channels)),\n",
    "        layers.Conv2D(512, (3, 3), strides=(1, 1), padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Conv2D(256, (3, 3), strides=(1, 1), padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Conv2D(128, (3, 3), strides=(1, 1), padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Conv2D(64, (3, 3), strides=(1, 1), padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.GlobalMaxPooling2D(),\n",
    "        layers.Dense(1),\n",
    "    ],\n",
    "    name=\"discriminator\",\n",
    ")\n",
    "\n",
    "# Create the generator.\n",
    "generator = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.InputLayer((generator_in_channels,)),\n",
    "        # We want to generate 128 + num_classes coefficients to reshape into a\n",
    "        # 7x7x(128 + num_classes) map.\n",
    "        layers.Dense(8 * 8 * generator_in_channels),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Reshape((8, 8, generator_in_channels)),\n",
    "        layers.Conv2DTranspose(64, (3, 3), strides=(2, 2), padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Conv2DTranspose(128, (3, 3), strides=(2, 2), padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Conv2DTranspose(256, (3, 3), strides=(2, 2), padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Conv2D(3, (4, 4), padding=\"same\", activation=\"sigmoid\"),\n",
    "    ],\n",
    "    name=\"generator\",\n",
    ")\n",
    "\n",
    "\n",
    "generator.summary()\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A print function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BtNoVhzbLOW2"
   },
   "outputs": [],
   "source": [
    "NUM_CLASSES = 3\n",
    "r, c = 5, NUM_CLASSES\n",
    "\n",
    "z_input = tf.random.normal(shape=(r*c, latent_dim))\n",
    "labels = np.asarray([0,0,0,0,0,1,1,1,1,1,2,2,2,2,2])\n",
    "labels = keras.utils.to_categorical(labels, 3)\n",
    "tot_noise = tf.concat([z_input, labels], axis=1)\n",
    "\n",
    "def save_image(generator, iteration, tot_noise):\n",
    "    NUM_CLASSES = 3\n",
    "    r, c = 5, NUM_CLASSES\n",
    "    \n",
    "    test_imgs = generator(tot_noise, training=True)\n",
    "    gen_image = (test_imgs * 0.5) + 0.5\n",
    "    count = 0\n",
    "    plt.figure(figsize = (15,7))\n",
    "    for i in range(5 * NUM_CLASSES):\n",
    "        plt.subplot(NUM_CLASSES, 5, i+1)\n",
    "        img_test = tf.keras.preprocessing.image.array_to_img(gen_image[i])\n",
    "        plt.imshow(img_test)\n",
    "        plt.axis('off')\n",
    "        if (i == 0 or i == 5 or i == 10): \n",
    "            plt.ylabel(class_names[count])\n",
    "            count +=1\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('./iteration'+ str(iteration)+'.png')\n",
    "    plt.show()\n",
    "        \n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def show_losses(d_loss, g_loss, iteration):\n",
    "    plt.figure(figsize=(10,4))\n",
    "    plt.plot(g_loss, lw=2, alpha=0.6, color='red', label='G')\n",
    "    plt.plot(d_loss, lw=2, alpha=0.6, color='blue', label='D')\n",
    "    plt.legend()\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss value')\n",
    "    plt.title('Losses')\n",
    "    plt.savefig('./Generated/losses'+str(iteration)+'.png')\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kGGZr0hAHcbE"
   },
   "source": [
    "## Creating a `ConditionalGAN` model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-10T09:59:33.579364Z",
     "iopub.status.busy": "2022-07-10T09:59:33.579008Z",
     "iopub.status.idle": "2022-07-10T09:59:33.600128Z",
     "shell.execute_reply": "2022-07-10T09:59:33.599157Z",
     "shell.execute_reply.started": "2022-07-10T09:59:33.579334Z"
    },
    "id": "OboS2SYqHcbF"
   },
   "outputs": [],
   "source": [
    "class ConditionalGAN(keras.Model):\n",
    "    def __init__(self, discriminator, generator, latent_dim):\n",
    "        super(ConditionalGAN, self).__init__()\n",
    "        self.discriminator = discriminator\n",
    "        self.generator = generator\n",
    "        self.latent_dim = latent_dim\n",
    "        self.gen_loss_tracker = keras.metrics.Mean(name=\"generator_loss\")\n",
    "        self.disc_loss_tracker = keras.metrics.Mean(name=\"discriminator_loss\")\n",
    "    \n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.gen_loss_tracker, self.disc_loss_tracker]\n",
    "\n",
    "    def compile(self, d_optimizer, g_optimizer, loss_fn):\n",
    "        super(ConditionalGAN, self).compile()\n",
    "        self.d_optimizer = d_optimizer           #Adam\n",
    "        self.g_optimizer = g_optimizer           #Adam\n",
    "        self.loss_fn = loss_fn                   #BinaryCrossentropy\n",
    "\n",
    "    def train_step(self, data):\n",
    "  \n",
    "        # Unpack the data.\n",
    "        real_images, one_hot_labels = data  #images e labels (specified in the fit method)\n",
    "  \n",
    "        # real images-labels\n",
    "        image_one_hot_labels = one_hot_labels[:, :, None, None]\n",
    "\n",
    "        image_one_hot_labels = tf.repeat(\n",
    "            image_one_hot_labels, repeats=[image_size * image_size]\n",
    "        )\n",
    "        image_one_hot_labels = tf.reshape(\n",
    "            image_one_hot_labels, (-1, image_size, image_size, num_classes)\n",
    "        )  #obtained a (64,64,3) tensor\n",
    " \n",
    "        # Sample random points in the latent space and concatenate the labels.\n",
    "        # This is for the generator.\n",
    "        batch_size = tf.shape(real_images)[0]  #immagini nel batch\n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim)) #batch random points of dimension Z\n",
    "        random_vector_labels = tf.concat(\n",
    "            [random_latent_vectors, one_hot_labels], axis=1\n",
    "        ) #all the input infos\n",
    "\n",
    "        # Decode the noise (guided by labels) to fake images.\n",
    "        generated_images = self.generator(random_vector_labels)\n",
    "\n",
    "        # Combine them with real images. Note that we are concatenating the labels\n",
    "        # with these images here.\n",
    "        fake_image_and_labels = tf.concat([generated_images, image_one_hot_labels], -1)\n",
    "        real_image_and_labels = tf.concat([real_images, image_one_hot_labels], -1)\n",
    "        combined_images = tf.concat([fake_image_and_labels, real_image_and_labels], axis=0)\n",
    "\n",
    "        # Assemble labels discriminating real from fake images.\n",
    "        # elenco del vero o falso\n",
    "        labels = tf.concat(\n",
    "            [tf.ones((batch_size, 1)), tf.zeros((batch_size, 1))], axis=0\n",
    "        )\n",
    "\n",
    "        # Train the discriminator.\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self.discriminator(combined_images)\n",
    "            d_loss = self.loss_fn(labels, predictions)\n",
    "        grads = tape.gradient(d_loss, self.discriminator.trainable_weights)\n",
    "        self.d_optimizer.apply_gradients(\n",
    "            zip(grads, self.discriminator.trainable_weights)\n",
    "        )\n",
    "\n",
    "        # Sample random points in the latent space.\n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "        random_vector_labels = tf.concat(\n",
    "            [random_latent_vectors, one_hot_labels], axis=1\n",
    "        )\n",
    "\n",
    "        # Assemble labels that say \"all real images\".\n",
    "        misleading_labels = tf.zeros((batch_size, 1))\n",
    "\n",
    "        # Train the generator (note that we should *not* update the weights\n",
    "        # of the discriminator)!\n",
    "        with tf.GradientTape() as tape:\n",
    "            fake_images = self.generator(random_vector_labels)\n",
    "            fake_image_and_labels = tf.concat([fake_images, image_one_hot_labels], -1)\n",
    "            predictions = self.discriminator(fake_image_and_labels)\n",
    "            g_loss = self.loss_fn(misleading_labels, predictions)\n",
    "        grads = tape.gradient(g_loss, self.generator.trainable_weights)\n",
    "        self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))\n",
    "\n",
    "        #self.save_images()\n",
    "\n",
    "        # Monitor loss.\n",
    "        self.gen_loss_tracker.update_state(g_loss)\n",
    "        self.disc_loss_tracker.update_state(d_loss)\n",
    "\n",
    "\n",
    "        return {\n",
    "            \"g_loss\": self.gen_loss_tracker.result(),\n",
    "            \"d_loss\": self.disc_loss_tracker.result(),\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vf0edOofHcbG"
   },
   "source": [
    "## Training the Conditional GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-10T09:59:37.684846Z",
     "iopub.status.busy": "2022-07-10T09:59:37.683749Z",
     "iopub.status.idle": "2022-07-10T09:59:37.699649Z",
     "shell.execute_reply": "2022-07-10T09:59:37.698442Z",
     "shell.execute_reply.started": "2022-07-10T09:59:37.684779Z"
    },
    "id": "OCvZKt_tRIqA"
   },
   "outputs": [],
   "source": [
    "cond_gan = ConditionalGAN(discriminator=discriminator, generator=generator, latent_dim=latent_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scheduled $\\eta$ exponential decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-10T09:59:40.794569Z",
     "iopub.status.busy": "2022-07-10T09:59:40.793853Z",
     "iopub.status.idle": "2022-07-10T09:59:40.808356Z",
     "shell.execute_reply": "2022-07-10T09:59:40.807202Z",
     "shell.execute_reply.started": "2022-07-10T09:59:40.794531Z"
    },
    "id": "Mwayh4yWHcbH"
   },
   "outputs": [],
   "source": [
    "initial_learning_rate = 0.0005\n",
    "\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate,\n",
    "    decay_steps=50,\n",
    "    decay_rate=0.99,\n",
    "    staircase=True)\n",
    "\n",
    "\n",
    "cond_gan.compile(\n",
    "    d_optimizer=keras.optimizers.Adam(learning_rate=lr_schedule, beta_1=0.5),\n",
    "    g_optimizer=keras.optimizers.Adam(learning_rate=lr_schedule, beta_1=0.5),\n",
    "    loss_fn=keras.losses.BinaryCrossentropy(from_logits=True),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "To do: define a callbacks list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-10T09:59:43.791109Z",
     "iopub.status.busy": "2022-07-10T09:59:43.789129Z",
     "iopub.status.idle": "2022-07-10T11:34:16.043618Z",
     "shell.execute_reply": "2022-07-10T11:34:16.042726Z",
     "shell.execute_reply.started": "2022-07-10T09:59:43.791059Z"
    },
    "id": "JoE9hEDim3Vr",
    "outputId": "040dbd67-8d5e-4792-b3c0-36998e973413"
   },
   "outputs": [],
   "source": [
    "save_image(cond_gan.generator, 9999, tot_noise)\n",
    "steps = 500\n",
    "g_loss = []\n",
    "d_loss = []\n",
    "\n",
    "for i in range(steps):\n",
    "    cond_gan.fit(dataset, epochs=1)\n",
    "    d_loss.append(cond_gan.disc_loss_tracker.result())\n",
    "    g_loss.append(cond_gan.gen_loss_tracker.result())\n",
    "    print(d_loss[i])\n",
    "    save_image(cond_gan.generator, i+1, tot_noise)\n",
    "    show_losses(d_loss, g_loss, (i+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save files (for kaggle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-10T11:35:55.080412Z",
     "iopub.status.busy": "2022-07-10T11:35:55.080038Z",
     "iopub.status.idle": "2022-07-10T11:36:02.448658Z",
     "shell.execute_reply": "2022-07-10T11:36:02.447741Z",
     "shell.execute_reply.started": "2022-07-10T11:35:55.080379Z"
    }
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "shutil.make_archive('Generated', 'zip', './Generated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n70Mngy2p_63",
    "outputId": "347bd148-28b1-42fb-f2be-b429b521b5e7"
   },
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    cond_gan.fit(dataset, epochs=1) \n",
    "    save_image(cond_gan.generator, iteration=99999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fUD1uOKsHcbI"
   },
   "source": [
    "## Interpolating between classes with the trained generator (from keras tutorial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-10T11:57:43.439679Z",
     "iopub.status.busy": "2022-07-10T11:57:43.43902Z",
     "iopub.status.idle": "2022-07-10T11:57:43.501242Z",
     "shell.execute_reply": "2022-07-10T11:57:43.500306Z",
     "shell.execute_reply.started": "2022-07-10T11:57:43.439641Z"
    },
    "id": "TBGAgcE8HcbJ"
   },
   "outputs": [],
   "source": [
    "# We first extract the trained generator from our Conditiona GAN.\n",
    "trained_gen = cond_gan.generator \n",
    "\n",
    "# Choose the number of intermediate images that would be generated in\n",
    "# between the interpolation + 2 (start and last images).\n",
    "num_interpolation =   10 # @param {type:\"integer\"} \n",
    " \n",
    "# Sample noise for the interpolation.\n",
    "interpolation_noise = tf.random.normal(shape=(1, latent_dim))\n",
    "interpolation_noise = tf.repeat(interpolation_noise, repeats=num_interpolation)\n",
    "interpolation_noise = tf.reshape(interpolation_noise, (num_interpolation, latent_dim))\n",
    "\n",
    "\n",
    "def interpolate_class(first_number, second_number):\n",
    "    # Convert the start and end labels to one-hot encoded vectors.\n",
    "    first_label = keras.utils.to_categorical([first_number], num_classes)\n",
    "    second_label = keras.utils.to_categorical([second_number], num_classes)\n",
    "    first_label = tf.cast(first_label, tf.float32)\n",
    "    second_label = tf.cast(second_label, tf.float32)\n",
    "\n",
    "    # Calculate the interpolation vector between the two labels.\n",
    "    percent_second_label = tf.linspace(0, 1, num_interpolation)[:, None]\n",
    "    percent_second_label = tf.cast(percent_second_label, tf.float32)\n",
    "    interpolation_labels = (\n",
    "        first_label * (1 - percent_second_label) + second_label * percent_second_label\n",
    "    )\n",
    "\n",
    "    # Combine the noise and the labels and run inference with the generator.\n",
    "    noise_and_labels = tf.concat([interpolation_noise, interpolation_labels], 1)\n",
    "    fake = trained_gen.predict(noise_and_labels)\n",
    "    return fake\n",
    "\n",
    "\n",
    "start_class = 0  # @param {type:\"slider\", min:0, max:9, step:1}\n",
    "end_class = 1  # @param {type:\"slider\", min:0, max:9, step:1}\n",
    "\n",
    "fake_images = interpolate_class(start_class, end_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O8qyy9kLHcbK"
   },
   "source": [
    "Here, we first sample noise from a normal distribution and then we repeat that for\n",
    "`num_interpolation` times and reshape the result accordingly.\n",
    "We then distribute it uniformly for `num_interpolation`\n",
    "with the label indentities being present in some proportion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the gif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-10T11:57:48.777373Z",
     "iopub.status.busy": "2022-07-10T11:57:48.776772Z",
     "iopub.status.idle": "2022-07-10T11:57:48.912896Z",
     "shell.execute_reply": "2022-07-10T11:57:48.91185Z",
     "shell.execute_reply.started": "2022-07-10T11:57:48.777333Z"
    },
    "id": "HlcKoNIJHcbL"
   },
   "outputs": [],
   "source": [
    "fake_images *= 255.0\n",
    "converted_images = fake_images.astype(np.uint8)\n",
    "converted_images = tf.image.resize(converted_images, (96, 96)).numpy().astype(np.uint8)\n",
    "imageio.mimsave(\"animation_fire_to_water.gif\", converted_images, fps=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-10T12:45:24.364581Z",
     "iopub.status.busy": "2022-07-10T12:45:24.363491Z",
     "iopub.status.idle": "2022-07-10T12:45:24.44443Z",
     "shell.execute_reply": "2022-07-10T12:45:24.442892Z",
     "shell.execute_reply.started": "2022-07-10T12:45:24.364452Z"
    },
    "id": "-LeDO479qtt1"
   },
   "outputs": [],
   "source": [
    "cond_gan.generator.save_weights('generator.h5')\n",
    "cond_gan.discriminator.save_weights('discriminator.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
